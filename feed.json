{
	"version": "https://jsonfeed.org/version/1",
	"title": "Art Kavanagh personal site",
	"home_page_url": "https://www.artkavanagh.ie/",
	"feed_url": "https://www.artkavanagh.ie/feed.json",
	"description": "Writing by Art Kavanagh — Fiction, criticism and book discussion",
	"items": [
		{
			"id": "body-in-the-matrix",
			"date_published": "2020-09-03T09:02:00+02:00",
			"title": "The body in The Matrix",
			"content_html": "<p>I saw <cite>The Matrix</cite> only once, on television in about 2001 or 2002. I was disappointed in the film, particularly compared to the Wachowskis’ earlier <cite><a href=\"https://thespool.net/features/2019/06/bound-wachowski-retro-review/\">Bound</a></cite>. Their first film a twisty, gripping banquet of a heist movie in which two women plot to steal mob money that’s being laundered by the husband of one of them. I’ve never seen Gina Gershon give a better performance than she does as Corky, and Jennifer Tilly slyly undermines her high-voiced, “girly” persona.</p><p>So I had high hopes for <cite>The Matrix</cite> but I’m sorry to say they weren’t realized. I found the film plodding, unsubtle and over-reliant on special effects, with a plot that seemed incomplete (as if the film-makers were holding back part of the story for the sequels). In particular, I found the “reality isn’t what you think it is, it’s something completely different” theme dissatisfying and fantastic (not in a good sense). I never bothered to watch the sequels. I always meant to go back and give <cite>The Matrix</cite> a second chance, to see if I’ve been unfair to it (a distinct possibility) but that has never seemed an urgent project in the 18 years or so since I saw it.</p><p>Then, recently, Jennifer Harrison (<a href=\"https://micro.blog/GeneticJen\">GeneticJen</a> on Micro.blog) reposted an essay that she had originally published on Medium 3 years ago, in which she examines the argument that <cite>The Matrix</cite> can be viewed as <a href=\"https://geneticjen.micro.blog/2020/08/21/some-thoughts-and.html\">a trans allegory</a>. That led me to Google, where I learned that there’s a whole online discussion of this very question that seems to have been going on for some time. One contribution that caught my eye was <a href=\"https://www.vox.com/culture/2019/3/30/18286436/the-matrix-wachowskis-trans-experience-redpill\">a story on <cite>Vox</cite> by Emily VanDerWerff</a>, who puts her finger on exactly what I don’t like about <cite>The Matrix</cite>:</p><blockquote>The entire movie is about transcending the limitations of the physical form to explore what the mind is capable of. Bodies are, at best, a suggestion. Your brain is what really matters.</blockquote><p>I fundamentally disagree that the brain is “what really matters” and the body little more than a bundle of limitations that exists primarily to be transcended. The idea that the body is just a adjunct to the “real” self (whether that self is conceived of as “the mind”, “the soul” or some other kind of inner essential being) is a commonplace in European thought, literature and religion. I have long believed that it’s completely wrong and treacherously deceptive.</p><p>A person’s body is central to the way she exists in the world. It initially registers the sensory inputs — sight, taste, sensation, hearing and smell — that the brain then processes. It includes (among much else) the digestive and cardio-vascular systems that keep the whole organism alive. It’s responsible for speech and all actions taken by the individual. If we assume that a disembodied brain <em>could</em> exist at all, it would be completely isolated from the world, unable to communicate, to perceive anything or even to nourish itself. It could not survive for very long.</p><p>Even in this last paragraph, I’ve been treating body and mind as if they were distinct parts of the human being, capable of having an existence separate from each other. This is not what I believe, but is simply a piece of conceptual shorthand. Body and mind are <em>both</em> integral and essential to the complete person. We are accustomed to think of them as distinct only for analytical purposes.</p><p>They’re really nothing more than ways of trying to grasp different aspects of the same big, complex, multifaceted, organic thing (the human individual) but they don’t in reality correspond to an actual division or divisibility within that thing. A body without a mind is a corpse; a mind without a body merely a fantasy.</p><p>That’s the main reason I’ve never been able to accept formulations like “born in the wrong body” (which mercifully one hears less often now that people wanting to transition have fewer gatekeepers to persuade). A living body is not a vessel or container <em>in</em> which the essential self is carried around. Nor is it a piece of organic machinery which is employed (for want of something better) by a ghostly intelligence to mediate between itself and the “external”, physical world. On the contrary, the body is an integral part of the human being, a part that can’t be separated or disentangled from the being as a whole.</p><p>I fully understand that this is not how the body appears to us in our self-perceptions. I’ve <a href=\"https://medium.com/p/2db66c17c5f3\">written before</a> more than once about <a href=\"https://medium.com/p/e0c93850ffb1\">not having a visual self-image</a>. I <em>do</em> have a self-conception, however, and I’ve been thinking a lot about what form that self-conception takes. It’s not easy to be sure, because the idea seems to slip away as I try to examine it directly. But, as far as I can tell, I imagine myself (at least some of the time) as a blob of consciousness, occupying the same physical position as my cranium but slightly larger and with less distinct edges.</p><p>Of course, that self-conception is <em>obviously wrong</em>. I’m perfectly well aware that it’s wrong. I <em>know</em> that I’m an overweight, white, Irish male, in need of a haircut and about 1.81 metres in height. But that’s not how I experience my own being. (When I was much younger, I used to enjoy the “Oh, <em>that’s</em> what I look like” moment when I’d unexpectedly catch sight of my reflection. For some years now, the surprise hasn’t been nearly so pleasant but it’s still a surprise.)</p><p>Now it’s possible that, because I can’t visualize, I have a more <em>obviously</em> distorted self-conception than most. Be that as it may, I’m convinced that people generally have an inaccurate and misleading image or conception of themselves. Why we as a species should have evolved that way I can’t say, but I’m not in any doubt that we have done so. For some reason, we seem to be better adapted to survival if we can manage to believe that “we” are insulated by our physical attributes from our environment, and that we exist somehow apart from it. Intellectually, we know that this is an illusion. We should try not to forget that fact.</p><p>Probably, this distorted self-image is one of the factors that makes it possible for us to devalue the body: to see our consciousness as the <em>essential</em> thing and our physical characteristics as incidental and subsidiary, just the container. In any case, I think it’s worth making a special effort to give the body its (easily overlooked) due. I think something like this is partly what J K Rowling had in mind when she provoked a lot of anger by <a href=\"https://www.jkrowling.com/opinions/j-k-rowling-writes-about-her-reasons-for-speaking-out-on-sex-and-gender-issues/\">insisting that “sex is real”</a>. Sex is, I suspect, the area of human activity and entity where the interdependence and inseparability of mind and body are at their most obvious and undeniable.</p><p>So, I interpret Rowling’s remarks as implying that “bodies are real, and indispensable”, and in that sense (though <a href=\"https://www.artkavanagh.ie/gender-identity.html\">not exclusively in that sense</a>) I fundamentally agree with it.</p><p>I think the time has come when I should finally rewatch <cite>The Matrix</cite>, with more critical attention than I gave it 18 years ago. Depending on how that goes, I might even watch the sequels. But I’m not going to be surprised if I don’t enjoy them.</p>",
			"summary": "I disliked and was disappointed in The Matrix, which I’ve seen only once, though I loved the Wachowski sisters’ earlier film, Bound. Vox’s Emily VanDerWerff may have put her finger on the reason I’ve been refusing the red pill. It has to do with transcending the body’s limitations.",
			"url": "https://www.artkavanagh.ie/body-in-the-matrix.html"
		},
		{
			"id": "poetry-scholarly-editions",
			"date_published": "2020-08-22T11:48:00+02:00",
			"title": "Reading poetry in scholarly editions",
			"content_html": "<p>In the discussions of poetry by <a href=\"https://medium.com/p/30b2093bc6c3\">Andrew Marvell</a> and <a href=\"https://www.artkavanagh.ie/finite-though-unbounded\">William Empson</a> that I’ve posted over the past few years, I have had to rely on scholarly editions of their poetry. In the case of Empson, I quoted from John Haffenden’s <cite>The Complete Poems of William Empson</cite> (Penguin, 2000) and for Marvell I used Nigel Smith’s <cite>The Poems of Andrew Marvell</cite>, revised edition, (Routledge, 2007). In each case, I found it necessary to replace the poetry quotations in my original draft/version of the post with the corresponding passages taken from the chosen edition. That was one of the factors that got me thinking (again) about scholarly editions of poetry.</p><p>For example, my original 1996 essay on Empson’s poetry quoted lines 11–12 of “Invitation to Juno” as</p><blockquote>Could not Professor Charles Darwin<br>Graft annual upon perennial trees?</blockquote><p>That version of line 11 is the one that appears in Empson’s <cite>Collected Poems</cite> (Chatto &amp; Windus, 1955) — very nearly the ideal form of a “slim volume”, with a beautiful yellow dust jacket — that I had used while writing the essay. For online publication, I substituted the version of line 11 from Haffenden’s edition:</p><blockquote>Did not once the adroit Darwin<br>Graft annual upon perennial trees?</blockquote><p>According to Haffenden, Empson changed line 11 because he was dissatisfied with the inaccurate characterization of Darwin as a “Professor”. So, “the adroit Darwin” accords with authorial intention, albeit an intention that crystallized many years after initial publication of the poem. I think Empson’s change is an improvement in one way and a disimprovement in another. (Probably the latter on balance.) It certainly gave me pause on first reading, because of my familiarity with the “Professor” version of the line.</p><p>The first edition of Nigel Smith’s <cite>The Poems of Andrew Marvell</cite> appeared in 2003 in hardback and I used it extensively while working on my doctoral thesis. But by then I had already adopted the practice of quoting Marvell’s poetry from an earlier scholarly edition, and I continued to use the earlier edition for quotations throughout my thesis. This was Margoliouth’s <cite>The Poems and Letters of Andrew Marvell</cite>, 3rd ed. by Pierre Legouis with E. E. Duncan-Jones (OUP, 1971). This edition, though impeccable in most respects, was 30 years older, dating from a time when scholarship tended to be less obtrusive.</p><p>One of the examiners of my thesis pointed out to me that to quote from the earlier edition, now that Smith’s was established as the new standard, appeared eccentric and wilfully anachronistic on my part. I decided that for further publication I needed to replace the quotations from Legouis/Margoliouth with the corresponding passages from Smith. I did so without entusiasm, but that is not to say that I don’t appreciate Smith’s contribution. I am not merely hugely indebted to the work of Haffenden and Smith, I am wholly in awe of it, to the point where I find myself in a position analogous to Marvell’s, when he acknowledged that he “must commend” Milton’s <cite>Paradise Lost</cite>:</p><blockquote>… I am now convinced, and none will dare<br>Within thy labours to pretend a share.<br>Thou hast not missed one thought that could be fit,<br>And all that was improper dost omit:<br>So that no room is here for writers left,<br>But to detect their ignorance or theft.<br>…</blockquote><blockquote class=\"indent\">Where couldst thou words of such a compass find?<br>Whence furnish such a vast expanse of mind? (“On … <cite>Paradise Lost</cite>”, ll. 25–30, 41–2)</blockquote><p>Yet, overwhelmingly impressive though their work is, I suspect that if I had first encountered Empson’s or Marvell’s poetry in one of these editions I wouldn’t have been quite so keen to write about it. I still feel that the “natural habitat” of Empson’s poetry is 119 small octavo pages, rather than Haffenden’s 512 somewhat larger ones. Several times while lightly editing the Empson essay before posting it on the web, I caught myself wishing that I had the 1955 <cite>Collected Poems</cite> within easy reach.</p><p>In much the same way, I noticed many years ago a reluctance on my part to reread one of Marvell’s poems in its entirety. Instead, I’d open the volume to check a line, a reference or an argument. For a while, I thought this was just ennui resulting from overexposure. But I’ve often suspected that there may be more to it than that.</p><p><img src=\"https://www.artkavanagh.ie/nymph-complaining.jpeg\" alt=\"The Nymph Complaining, Smith’s edition\" width=\"640\" height=\"580\"></p><p>This is the opening from the Smith edition of one of my favourite poems, “The Nymph Complaining for the Death of her Fawn”. Without wishing to appear in the least ungrateful for Smith’s painstaking work, I can’t help feeling that Marvell’s lyric is a bit cramped or constrained by the weight of scholarship that surrounds it. If I was approaching “The Nymph Complaining” for the first time, I suspect that I’d find this presentation, with its dense context, just a little forbidding. And one of the problems with reading poetry is that even very small obstacles can derail an attempt to take it in.</p><p>This gives rise to a real dilemma. A mid seventeenth century poet like Marvell can appear deceptively modern: the twenty-first century reader is often at risk of mistaking the poet for our near-contemporary, and therefore misreading his work. I need to be periodically reminded that the culture of print publication, the system of censorship and “licensing”, the constitution of Parliament (of which Marvell was a member for the last 20 years of his life) and the meaning of the word “constitution” itself (to take just some of the more obvious examples) each had a different significance for Marvell than it may have for me.</p><p>Historical scholarship provides some protection against this kind of misinterpretation and is therefore indispensable. But I suggest we need a way to hide it so that it doesn’t make its presence felt too early in the reading process. One possibility would be to start reading the poetry from a popular edition (or, as I did with Marvell, from an earlier scholarly one). But the popular or outdated edition probably contains readings that have since been questioned or rejected, and will ignore the most recent discoveries.</p><p>Ideally, the reader and discusser of the poetry needs the most up-to-date text, but separated (to the extent it can be) from extraneous commentary and annotation. There are some obvious ways this could be achieved. Publishers might divide their scholarly editions into two volumes, one containing only the poetry, the other the scholarly apparatus. Depending on the needs of the reader, both volumes could be opened and read side by side, or one could be consulted at a time. Another possibility would be to produce just one volume, containing the “bare” text of the poetry, with the critical and scholarly material being made available online.</p><p>Some 20 years ago, I owned a large, thick paperback, <cite>The BeOS Bible</cite> by Scot Hacker. Purchasers of the printed book could get access to supplementary and updated material on the publisher’s website. As far as I remember, I didn’t make much use of the online material. I probably thought that the approach was something of a gimmick. Twenty years on, I think I may see a use for that approach.</p>",
			"summary": "Scholarly editions of poetry provide some protection against anachronistic readings, misinterpretation and other errors. Unfortunately, that protection comes at a price.",
			"url": "https://www.artkavanagh.ie/poetry-scholarly-editions.html"
		},
		{
			"id": "gender-as-behaviour",
			"date_published": "2020-08-13T08:24:00+02:00",
			"title": "A good masculinity is hard to find: Part 3 — gender as behaviour",
			"content_html": "<p>For most of my adult life — at a conservative estimate, from my mid 20s to my late 50s — I’ve thought of gender as predominantly a question of <em>behaviour</em>: certain clusters of actions, attitudes, proclivities, beliefs and traits can be categorized as more or less masculine, others as more or less feminine. As I said in part 2, the notion of gender-as-identity was completely foreign to me, something I had never considered.</p><p>When I first started to think about gender (masculinity/femininity) as something distinct from sex (male/female) in the mid 1980s, it seemed clear that in this schema <em>sex</em> was entirely a matter of biology. It was the way our species reproduces itself, the mechanism by which the next generation was brought into existence. If you weren’t born with a uterus and ovaries, there was no possibility that you could ever bear a child. Conversely, throughout most of human history, without testes and a penis you were never going to fertilize an egg. Sex was straightforward and (a relatively small number of intersex people apart) obvious. The vast majority of people were either male or female and were going to stay that way, whether they liked it or not. And, strange as it might seem from today’s viewpoint, that was no big deal.</p><p>Because, if sex was reproduction, <em>gender</em> was more or less everything else. Whether you preferred to wear dungarees and short spiky hair, or frilly dresses with ringlets down to your waist; whether you shaved your legs and armpits or the bottom half of your face; and whether you listened to death metal or showtunes: none of these had any <em>necessary</em> connection with whether you had a womb or not. And if the male/female stuff was all about biology, the masculine/feminine characteristics and activities must be … well, they must be the opposite. That meant they must be sociocultural.</p><p>If you were solicitous and nurturing, accustomed to putting the needs of your family members before your own desires; or, on the other hand, if you were assertive and belligerent, and wary about being taken advantage of, this wasn’t the product of genes or chromosomes, but rather of your social conditioning. If you were a macho hard man, it was because “society” (for its own inscrutable purposes) was always nudging you in that direction.</p><p>I stuck with this model of gender for several decades, despite the lack of evidence to support it. If gender was a matter of social conditioning, it ought (presumably) be easy enough to decondition ourselves as a society. Don’t give your boy children toy guns and trucks to play with, or your girl children dolls’ houses and nurses’ outfits. Don’t dress them in blue or pink. Don’t encourage the boys’ ambitions more than the girls’ or the girls’ caring, self-sacrificing side more than the boys’. And so on. I don’t have any statistical evidence, but I believe that most parents who have tried this approach would agree that it hasn’t been a spectacular success.</p><p>Say we accept that gender-as-behaviour is primarily a matter of social conditioning. Is that <em>in itself</em> a good enough reason to want to change it?  After all, there are many phenomena whose continued existence we accept despite the fact that they are largely social constructs: the stock market, academia, the film industry and the international law of the sea, to take a few examples. In other words, if it’s true that gender is something we’d like to free ourselves from, that isn’t because it’s “merely a social construct” but is more likely to be because we experience it as a limitation on our freedom: a set of shackles. And equally, if it turns out that gender really <em>is</em> merely a social construct, I don’t believe that it will therefore be easier to escape from it. In short, the supposed (unproven) social nature of gender may be a red herring.</p><p>Since the early 1960s, many women have come to see femininity as a trap, or as a set of constraints on what they can do and what they can be. In the decades since then, women have remade and redefined femininity, turning it into something that would appear unrecognizable to their 1950s foremothers. For the most part, they have freed themselves from its chains. In doing so, women did not become men (or become like men), though that is what many of the critics of feminism accused them of attempting. It’s striking that we men haven’t accomplished anything comparable in relation to masculinity. That imbalance between women’s considerable success in escaping femininity and men’s failure to get out from under the weight of masculinity requires some explanation.</p><p>It is, no doubt, partly a matter of men’s refusal to relinquish our advantageous gender position. Privilege of any kind has never been a easy thing to surrender voluntarily and it’s clear that the imbalance in gender relations — patriarchy, in short — has historically benefited men at the expense of women. Women have had much more incentive to shake off behavioural gender than we men have. Of course, it’s not as simple as that. In many areas of life (law, politics, business for example), older men have a historic advantage which is rapidly being eroded. As these old men retire, they will be replaced by a much more sex-balanced cadre. The privileges of masculinity have an expiry date and it’s getting closer all the time. And yet a substantial proportion of the younger male lawyers, politicians, executives etc. seem hardly any less dedicated to masculine behaviour than their predecessors were. Why should that be?</p><p>Based on my own experience as a male person (and a man), it does seem to me that a man who wishes to act in an obviously unmasculine way risks breaking a powerful taboo. I suspect that that acts as a strong check on any impulse we might have to reject masculinity. To be sure, those women in the 1960s and 70s who first attempted to jettison their feminine ways of dressing, acting and being also had to be willing to contravene taboos. Somehow the taboos which enforced and protected femininity were more vulnerable to attack than those doing the same job for masculinity. No doubt this was partly because women had less to lose and more to gain immediately. There may be more to it than that.</p><p>My former conception of gender as a social construct has not been easy to give up, notwithstanding the absence of supporting evidence. There wasn’t an identifiable moment when the scales dropped from my eyes. But gradually, unnoticed, I stopped thinking of gender as the product of “nurture” and began to wonder if it might not be innate. Quite likely, my fruitless search for a gender “identity” played a part. No doubt reading several books by Steven Pinker, including <cite>The Blank Slate</cite> which describes how many of the aspects of our personalities that we’re used to thinking of as learned behaviour actually come preinstalled by our genetic makeup, also had something to do with it.</p><p>This is my alternative suggestion. Think about the behaviour and attributes that are stereotypically masculine: strength and bulk, larger size, belligerence and assertiveness, self-confidence. A willingness to defend one’s corner and a wariness and suspicion about being cheated. In a developing early human society, before the institution of laws, tribunals, markets, councils of elders and so on, isn’t it likely that men who exhibited such masculine traits would enjoy an evolutionary advantage? Competing men would be more easily deterred from trying to steal their food, occupy their land, abduct their wives or daughters, or generally to make their lives more difficult.</p><p>Similarly, women who exhibited stereotypically feminine qualities, who were caring and nurturing, gentle, unthreatening, pretty, selfless and generous (and so on) would be more likely to attract the protection of the very masculine man, and thus share in his relative invulnerability to theft, dispossession, abduction and other adverse events. Couples like this could be expected to outbreed their rivals and pass their genes on to future generations. Furthermore, those couples amongst them who passed on the masculine characteristics disproportionally to their sons and the feminine ones disproportionally to their daughters would be more favoured by evolution than those who passed these qualities on indiscriminately. Random mutation would tend to select for masculinity in men and femininity in women.</p><p>This is what some critics of evolutionary biology have called a “just-so story”. It’s more in the nature of a thought experiment than a serious, testable hypothesis. I’m not claiming that such an evolutionary process as I’ve briefly described is an accurate or reliable account of how gendered behaviour and traits came to be so prominent in humans. I have no evidence to support this account. I believe it’s certain to be wrong in some significant respects. But —</p><p>Its purpose is to show that it’s <em>possible</em> to postulate a genetic or biological explanation of gender differences in human beings that is no more fanciful than the “social” explanation. I don’t know whether human gender differences are the result of socialization or biology (or of each reinforcing the other, or some more complex interaction of the two). I would like to <em>assume</em> for the sake of argument that our gender behaviour is as much a product of our biology as our reproductive organs are. If that were true, would it be an argument for accepting and acquiescing in the gender characteristics that we’ve presumably inherited from our ancestors? If both sex <em>and</em> gender are innate/genetic, shouldn’t we just abandon the idea that there’s a useful distinction to be made between them, that there’s any point in trying to keep them separate?</p><p>It seems to me that the answer is clearly “no”. We’re not yet finished with sex (always assuming that we think it’s a good thing that our species should continue to reproduce and propagate itself into the future). It still has a function to perform. Conversely, gender evolved, according to my hypothesis, because it made us safer in dangerous circumstances, circumstances very different from the ones we find ourselves in now that we have laws and institutions which provide a more effective protection than a bellowing, chest-thumping individual could hope to. Why should we continue to wear a gender straitjacket which no longer carries any compensating benefit? As I’ve said, women saw more than half a century ago that, in general, there were no advantages and considerable costs to retaining “femininity”. Men (in general) have been much slower to shake off masculinity, though for us too the costs far outweigh the (real, if quickly depreciating) advantages.</p><p>In recent years, the old-fashioned idea of gender-as-behaviour (which seemed new and exciting to me just 35 years ago), has been overshadowed by the concept of gender identity. My aim in these posts has been to argue that there are useful and important things still to be said about the older notion. While gender identity issues affect a relatively small proportion of the population, virtually everybody is or has been, to some extent, a prisoner of gender behaviour. The much greater visibility of transgender people in recent years is welcome for many reasons, not least (from my point of view) because it makes gender nonconformity a more socially acceptable choice for the rest of us. But it also comes with at least one major risk: that <em>only</em> trans people will be perceived as needing to escape from gender, and that the rest of us will continue to tolerate, with only relative discomfort, our accustomed gender constraints. It’s time we recognized that there are varying degrees (and quite possibly different kinds) of gender dysphoria, and that virtually all of us are affected by some variety of that condition to some significant extent.</p><p>Though this is the last post in the series, there remain things I wanted to say about gender (and possibly also about sex). So there may be further standalone posts in the near future. You have been warned.</p>",
			"summary": "The old-fashioned notion of gender-as-behaviour has recently been overshadowed by the concept of gender identity. But there are still useful things to be said about the older idea. For a start, having believed for more than 35 years that masculinity and femininity were “social constructs”, I’ve recently changed my opinion.",
			"url": "https://www.artkavanagh.ie/gender-as-behaviour.html"
		},
		{
			"id": "prelate",
			"date_published": "2020-08-02T09:35:00+02:00",
			"title": "Prelate of the grove: A note on ambition and preferment in Marvell’s Upon Appleton House",
			"content_html": "<p>Andrew Marvell was no admirer of bishops. Examples of his antipathy can be found throughout his writings, for example in his “Epigram: Upon Blood’s attempt to steal the Crown”. This verse was occasioned by an incident in 1671, when Colonel Thomas Blood entered the Tower of London with the aim of stealing the Crown jewels. Blood was disguised as a priest, “The fittest mask for one that robs a crown” (l. 4). If he had killed the keeper of the Tower instead of just wounding him, he might have escaped with the jewels. (He was subsequently pardoned by the king.) Marvell comments:</p><blockquote>With the priest’s vestments, had he but put on<br>A bishop’s cruelty, the crown had gone. (ll. 7–8)</blockquote><p>The Blood epigram is included in it entirety as lines 192–199 of “The Loyal Scot”, Marvell’s poem on the death of Captain Archibald Douglas in a Dutch attack on Chatham in 1667. In that poem bishops are portrayed as a major cause of division between England and Douglas’s native Scotland. The reader is left in no doubt as to Marvell’s contempt:</p><blockquote>In faith erroneous, and in life profane,<br>These hypocrites their faith and linen stain. (ll. 170–171)</blockquote><p>One of the things that angered Marvell was the bishops’ insistence on interfering in the legislative process by taking seats in the House of Lords, when they might be expected to provide leadership in matters of faith. In ”The Third Advice to a Painter” (1666), he wrote:</p><blockquote>The Lords’ House drains the houses of the Lord<br>For bishops’ voices silencing the Word. (ll. 241–242)</blockquote><p>It is true that this complaint is uttered by Marvell’s “Cassandra”, rather than by the authorial voice, but there is no doubt that it reflects the poet’s own opinion: compare lines 224–225 of “The Loyal Scot”.</p><details><summary>Note: “Cassandra”</summary>On Lady Albemarle’s role as a truth-teller fated not to be believed, see Martin Dzelzainis, “‘Presbyterian Sibyl’: Truth-telling and Gender in Andrew Marvell’s <cite>The Third Advice to a Painter</cite>”, in <cite>Rhetoric, Women and Politics in Early Modern England</cite>, ed. Jennifer Richards and Alison Thorne (London and New York: Routledge, 2007), 111–28.</details><p>“Upon Appleton House” is earlier than any of these poems, dating from the summer of 1651. Marvell was already a critic of episcopacy but his attack here may seem a little less vituperative than the later ones. Instead of taxing the former occupant of Cawood Castle with cruelty or hypocrisy, Marvell instead draws attention to his ambition, a quality that might be undesirable in a bishop but which had its role to play in the personality of a retired general or his daughter.</p><blockquote>The sight does from these bastions ply,<br>Th’invisible artillery;<br>And at proud Cawood Castle seems<br>To point the batt’ry of its beams.<br>As if it quarrelled in the seat<br>Th’ambition of its prelate great. (ll. 361–364)</blockquote><p>The tone of this passage is not easy to pin down. The battery consists of the colours of banks of flowers, joyful rather than warlike. “As if” reminds the reader that the quarrel is imaginary, not least because “the seat” has not been occupied by the archbishop since the war started, some nine years earlier. Yet, there are real grounds for thinking that ambition is dangerous. Fairfax</p><blockquote>… did with his utmost skill,<br>Ambition weed, but conscience till.<br>Conscience, that heaven-nursèd plant,<br>Which most our earthly gardens want. (ll. 353–356)</blockquote><p>The contrast seems to be clear: conscience is to be cultivated, ambition rooted up and destroyed. However to “weed” ambition is not necessarily to treat it as a weed — it might be to pull up the weeds (such as presumption) which surround it, and give it space to grow healthily. That the poet is not critical of ambition in all circumstances becomes clear at the end of the poem, where Fairfax’s estate is urged to:</p><blockquote>Employ the means you have by her,<br>And in your kind yourselves prefer;<br>That, as all virgins she precedes,<br>So you all woods, streams, gardens, meads. (ll. 749–752)</blockquote><p>The woods, streams, gardens and meadows of Nunappleton do not as a matter of course surpass the various wonderful places that are listed in the following stanza. If they are to do so, they must actively “prefer” themselves, and the poet exhorts them to do so. The complexity of Marvell’s views on ambition and preferment may be seen in stanza LXXIV:</p><blockquote>The oak leaves me embroider all,<br>Between which caterpillars crawl;<br>And ivy, with familiar trails,<br>Me licks, and clasps, and curls, and hales.<br>Under this antic cope I move<br>Like some great prelate of the grove. (ll. 587–592)</blockquote><p>Earlier, in lines 365–6, Marvell has associated prelacy with the kind of ambition that might provoke a quarrel. In the light of this, and of Marvell’s known hostility to bishops, it is a little surprising that his speaker in “Upon Appleton House” refers to himself as a prelate. The word is related to “prefer”, deriving from the past participle of <span class=\"latinate\">praeferre</span>, to carry before. The speaker resembles a “prelate <em>of</em> the grove” (emphasis added) because he presents the appearance of having been preferred <em>by</em> the grove, which has crowned him with oak, classically the reward for civic virtue. The sense of these lines is thus very close to that of the beginning of “The Garden”, where the poet jokingly berates those who are ambitious to be</p><blockquote>Crowned from some single herb or tree,<br>Whose short and narrow vergèd shade<br>Does prudently their toils upbraid; (ll. 4–6)</blockquote><p>Ambition is mocked but ambivalently: the speaker’s recommendation, in “The Garden”, of a complete withdrawal from all society cannot be taken literally, however attractive it might temporarily appear; and it is clear from the Lovelace poem that the loss of “the civic crown” is not something that Marvell looks on with equanimity. The implication of the references to ambition in “Upon Appleton House”, taken together, is that the drive for preferment will usually be a dangerous temptation, but not invariably so, and that the need to discern when it is appropriate and when not calls for the development of an acutely discriminating conscience.</p>",
			"summary": "The treatment of ambition and preferment in Marvell’s “Upon Appleton House” indicates the need to develop an acutely discriminating conscience.",
			"url": "https://www.artkavanagh.ie/Prelate.html"
		},
		{
			"id": "writing-plain-text",
			"date_published": "2020-08-01T11:04:00+02:00",
			"title": "Writing plain text",
			"content_html": "<p>I’m back in the south-west of France after having spent the whole of the last 5 years in Ireland. At the moment, I’m in Pau, which is a couple of hours by train from where my sister and her family live. When I originally went back to Ireland nearly 9 years ago, I left a lot of stuff at my sister’s: a HP LaserJet printer, an amplifier and two speakers, several boxes of books … and an AlphaSmart Neo. I’ve been trying to remember whether the Neo was still working when I left. In principle, I can’t see any reason why it shouldn’t have been.</p><p>I like the idea of a device like the AlphaSmart, which just writes text. In practice, though, I’ve never found it all that satisfactory. In the early 00s, years before I bought the Neo on eBay, I had another AlphaSmart, the 3000. At once rugged and lightweight, it was supremely portable. In my imagination, I could just throw it in a backpack and head for the British Library, the Public Records Office or any other congenial spot, and start writing or taking notes. The catch was that while the 3000’s keyboard felt very comfortable to use, it made an unholy racket. Exactly not what you need in a library, particularly the British Library, with its large reading rooms. So instead I started to take a Palm Vx, with a folding keyboard that wasn’t nearly as easy to type on, but was almost silent. Since I finished my thesis, I haven’t been going to libraries nearly as much, so I’ve occasionally found myself thinking that maybe it was time to look again at the AlphaSmart.</p><p>Joel Spolsky said <a href=\"https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/\">there’e no such thing as plain text</a>. Of course there isn’t: whatever you write on a computer necessarily uses some kind of encoding. I can remember (not that long ago) sending a “plain” text document to a Windows user who couldn’t make any sense of it because each subsequent line was superimposed on the first. (Or something like that: I can’t remember the details.) Windows expected a carriage return and a line feed, but was getting only the first of these. Of course, there are many Windows text editors that can fix the line endings, but my correspondent merely double-clicked on an email attachment and it opened by default in Notepad.</p><p>Recently, the encoding I’ve been using is UTF-8, and it’s so much better than what we used to have to put up with. Quite apart from accented characters — did I mention that I’m in France? — and diacritics, I can easily type dashes (both em and en), spaces (ditto), curly quotes, ellipses and pretty well anything I want. I’ve never tried to do any of these things on the Neo but I’m fairly sure it won’t cope with Unicode. That in itself is a good enough reason for me to leave it gathering dust in my sister’s house. It’s a pity but … it’s not as if I’m stuck for lightweight, portable means of writing unformatted text. I’m writing this post in Tot on an iPad Air (in portrait orientation) using a Logitech K380 Bluetooth keyboard. The keyboard is quiet and a joy to type on. I could equally have used a MacBook Air but, because I’m writing at dead of night in a hotel room without soundproofing, they keyboard’s quietness is an essential quality. The MacBook (mid 2019, with butterfly keys) makes a noise strongly reminiscent of the AlphaSmart 3000. If I write “plus ça change …”, it’s only so that I can show off my cedilla.</p>",
			"summary": "For the past few years, I’ve been doing most of my writing as unformatted text, what some people still insist on describing as “plain”. Sounds like it might be time to dust off the old AlphaSmart, if it still works. But can it cope with UTF-8?",
			"url": "https://www.artkavanagh.ie/writing-plain-text.html"
		},
		{
			"id": "tech-disconsolations",
			"date_published": "2020-07-29T09:23:00+02:00",
			"title": "Tech’s unfulfilled promises",
			"content_html": "<p>I’ve been enthusiastic about technology for most of my life. Since 1993, it’s been the main way I’ve made my living. Even before that, I thought of technological progress as, on balance, something which was clearly of benefit to the world. It offered the possibility of greatly increasing the productivity of human work, eliminating repetitive and boring tasks, reducing the length of the working week and expanding economic activity and with it the range of potential human achievement. It opened up the prospect of enriching humanity, both materially and psychoculturally.</p><p>Of course, because we would still be living under capitalist relations of production, the benefits of technology would not be evenly distributed. The already rich would arrogate the lion’s share of the newly created wealth, while the growth in leisure time resulting from increased productivity would be out of the reach of the majority of workers. But these two factors — the concentration of wealth in the hands of the obscenely rich and the grossly disproportionate allocation of “free” time, would themselves undermine the stability of the “relations of production” that brought them about. They’d lead to a revolution. Probably not in my lifetime but certainly in someone’s.</p><p>Perhaps coincidentally, it was around the same time as I actually started to work in a tech field that my optimism about the approaching global revolution began to wane. The collapse of communism, Tony Blair’s removal of clause 4 from the British Labour Party’s constitution and a variety of less tangible factors all no doubt played a part in the fading of my revolutionary fervour. It’s a weird feeling to undergo a fundamental change in one’s world view. You can’t just replace all your beliefs all at once. Gradually, you find that you have some convictions that seem deeply held, even though the foundation they previously rested upon has been broken up and carted off.</p><p>For example, while I am a historical materialist no longer, I have retained an unshaken commitment to materialism. I used to joke that I dropped the “historical” because I belatedly realized how little I actually knew about history. It’s perfectly true that my historical knowledge was gravely inadequate (as I confirmed when I began to write a doctoral thesis on a mid-seventeenth-century English poet) but that doesn’t really explain my political shift, which really came about as it became increasingly obvious that marxism wasn’t filling an urgent psychological need for me.</p><p>However that may be, my materialism survived the change in my beliefs and continues to do so 27 years later. It’s the reason why the last word of the first paragraph above isn’t “spiritually”, but a less satisfactory alternative. Similarly, most of my economic convictions have remained strong, even though I’ve long forgotten the marxist premises on which they were originally founded. Admittedly those convictions took a drubbing in the years following 2008, when they seemed to predict that global capitalism could not possibly survive the great destruction of capital brought about by the reckless gambling of risk-hungry financiers. (“Risk-hungry” that is, until the bets started to go wrong, at which point they clamoured for a bail-out, insisting that their gambles should be retrospectively guaranteed by the world’s governments.)</p><p>Capitalism continued for at least another decade, though I can take some comfort from the many indications that I was’t the only one to believe it was finally toppling over the precipice. The behaviour of the ultrarich in the years since the crash unmistakably indicates that they’ve abandoned hope of maintaining a sustainable balance of demand (spending) and wealth-extraction (or, as economists call it, “saving”) but have instead opted to grab as much loot as they can as fast as they can. The plutocrats have given up on capitalism, so maybe the rest of us should trust their judgment as to their best interests. Maybe, instead of a proletarian revolution, we’re seeing the early stages of a “top down” one, in which the will of the exploited to to pull down the system is less important than the failure of will of the exploiters to continue to hold it up.</p><p>It might seem that, having started to write about technology, I’ve veered off into a rant about economics and politics. However, these topics are inextricably interconnected. Technology, including information technology, robotics and machine learning, can be expected to cut the costs of production throughout the global economy. But if these reductions in costs are mainly realized in the layoff of workers, then the amount being paid in wages and salaries will drop. Since the people with the least disposable income are the people most likely to spend what they have, the layoffs can be expected to bring about a failure of demand, probably leading to a fall in real prices and offsetting the productivity gains. The new wealth will be destroyed almost as soon as it can be created.</p><p>Normally, you’d expect the capitalist governing class to do something to try to balance this out, with the aim of preserving or sustaining the system that has rewarded them so well. But for several decades now, and particularly since the crash of 2008, this is not what has been happening. Instead the global capitalist class has been allowing a huge, destabilizing disparity of wealth and income to develop. It’s starting to look as if the ultimate capitalist economic crash may finally be imminent. It’s been a long time coming. On the other hand …</p><p>Up to this point, I have been assuming that the gains in productivity brought about by technology are real, but I’m not at all convinced that this is in fact the case, for several reasons. First, tech brings with it a new set of problems to be dealt with, from spam and malware, through security and privacy threats to an increasing alienation on the part of the workers who use the technology, as its workings become ever farther removed from them. I’ve <a href=\"https://www.linkedin.com/pulse/from-tech-text-art-kavanagh/?trackingId=isO7OOBjSBEppLoLwLaDNA%3D%3D\">written recently</a> about the people working in law firms who use Word as if it were a kind of digital typewriter — even though very few of them are old enough ever to have used a real typewriter.</p><p>As a cornerstone of Microsoft’s Office suite, Word is a good example of what I’m talking about. During my early years working in tech, Microsoft was the most successful tech company in existence, led by Bill Gates, then the world’s richest man. It’s worth remembering that Gates’s current philanthropic activities are founded on the fortune he made from Microsoft’s ruthless, hardheaded business practices. At the time, his company seemed destined to dominate the business world for another two decades. Its two great money-spinners were its Office suite and Windows operating systems, both of which were thought to be essential software for any serious business.</p><p>In effect, Microsoft made Gates extremely wealthy by extracting rent from the business world for the use of these two sets of products. If this software did, in fact, bring about a great increase in the productivity of office work, it’s clear that by far the largest beneficiary of that increased productivity is the company that made the software! This is a pattern that is repeated with variations throughout the tech economy.</p><p>Microsoft’s dominion came to an end earlier than most of us expected, because the company underestimated the significance of the worldwide web. The company that <em>did</em> take the web seriously enough to develop a way to find useful information in its unstructured, pathless vastness, has made billions of dollars a year by ensuring that advertisers pay as much as they can bear to appear in its search results and on the websites whose advertising it controls. The current richest man in the world runs a company whose mission is to destroy retail and build a monopolistic “everything store”. While Google at least supplies something essential (though <a href=\"https://www.artkavanagh.ie/Google-future-search.html\">far from being as useful as it might be</a>), its main competitor for the world’s advertising budget provides little more than an opportunity for billions of people to produce (for no pay, of course) unimaginable quantities of “user-generated content” in which the ads can be embedded, as well as the ubiquitously tracked eyeballs that help to persuade the advertising managers that they’re actually paying for something useful. If this is a good bargain for the “user”, how can it have made Facebook so rich so quickly?</p><p>Another of my unprovable suspicions is that, if information technology has made work more productive for anybody, it has done so largely for those whose occupation is the production of yet more information technology. This thought struck me when I was trying to anticipate the objections that readers of this post might raise. Rightly or wrongly, I imagined the objectors as people who themselves work in tech. They’re the ones who see the benefits — to their own lives. For most of the rest of us, the effect of the great advances of recent decades has been felt mainly in the fields of entertainment and leisure: fast gaming machines, streaming audio and video, distracting and addictive social media, same-day delivery of our impulse purchases and sleek, powerful computers that we carry around in our pockets and use to help the likes of Uber, AirBnB and food delivery companies to destroy established businesses and replace them with a void. Tech has, overwhelmingly, given us circuses rather than bread.</p><p>So, have the developments in tech over the past 40 years or so been a net benefit for the world? Probably, but it’s very difficult to be sure. It’s certain, though, that the costs have been greater than we collectively expected (otherwise we’d collectively have tried harder to control them). As far as I personally am concerned, I feel that 27 years is more than enough time for me to have spent on tech. Of course, it wasn’t a full 27 years. For most of it, I was working part-time, and doing other things in tandem with it. My doctorate, for example. (The fact that it took me 15 years to complete is entirely down to me, and I don’t regret not having finished it sooner.) At the very least, working in tech provided me with the means to pursue other activities. But enough is enough. It’s time to find something else to do with what’s left of my life.</p><p>I set out to write a post about my own personal disenchantment with technology and instead found myself revisiting politico-economic assumptions and arguments that I thought I’d left behind long ago. I’m more than a little surprised at how well those assumptions and arguments stand up, so many years later. I think I stuck with tech so long, apart from the usual reason of inertia, because I fetishized productivity. The belief that increased productivity of work would make it possible to free the majority of our species from the drudgery and tyranny of labour (always assuming that those gains could be distributed more evenly than they have ever been up to now), is another one of those fundamental assumptions that seem to have survived the demise of my revolutionary convictions. But perhaps we already have all the productivity that we need. Perhaps the world is already rich enough to free its population from the need to work in boring, unfulfilling, physically demanding, dangerous, health-destroying occupations.</p><p>I believe it’s time to stop pursuing gains in productivity and turn our collective attention to the problem of more equitably allocating those we have already accumulated. Who knows, maybe Bill Gates feels the same?</p>",
			"summary": "Tech held out the promise of helping to free humanity from drudgery, boredom and hard physical work. Obviously, that promise hasn’t been kept. So, what now?",
			"url": "https://www.artkavanagh.ie/tech-disconsolations.html"
		},
		{
			"id": "gender-identity",
			"date_published": "2020-07-12T11:47:00+01:00",
			"title": "A good masculinity is hard to find: Part 2 — gender as identity",
			"content_html": "<p>In <a href=\"https://www.artkavanagh.ie/a-good-masculinity-anti\">part 1 of this series of posts</a>, I recalled that a trans woman who commented on an old post of mine had two main points to make against it. First, if I didn’t want to be described as “cisgender”, it was up to me to come up with an alternative term. The phrase I eventually settled on is “antimasculine male”, and I’ll have more to say in part 3 about why I've adopted that terminology. Her second point was that my post was entirely focused on gender <em>roles</em>, and that I “needed” to think about gender <em>identity</em> too. That’s the point I want to deal with in this part.</p><p>She was right: I hadn’t until then thought about gender as identity, though I had been thinking regularly (sometimes, it seemed, almost obsessively) about gender for at least thirty-five years. So I began to try to look at the subject from this new perspective.</p><p>I found that I was contemplating gender identity from the point of view of an outsider. I quickly discovered that <a href=\"https://medium.com/p/e0c93850ffb1\">a sense of gender identity is something that I personally don’t have</a>, which is one good reason why I’d never previously paid it any attention. I’ve speculated that this might be because I don’t have a visual imagination (or, in consequence, any kind of visual self-image). I haven’t been able to find a completely convincing answer to that puzzle, but I have learned that <a href=\"https://medium.com/p/d337512176d\">the “lack” of a sense of gender identity isn’t all that unusual</a>.</p><p>But thinking about gender identity from this outsider’s viewpoint has led me to speculate whether the astonishing virulence and vituperation of the online (and real-world) battles between so-called TERFs (mainly veteran feminists), on the one hand, and trans rights activists on the other has to do with a clash of contested identities.</p><p>When I was a teenager and in my early 20s in 1970s Ireland, it was vanishingly rare to hear an adult human female described as a “woman”. If she was under, say, 38, she was most likely to be a “girl”. Alternative terms were bird, chick, dollybird, cheescake, a bit of fluff/stuff and so on ad infinitum. There were fewer terms for older women but for the most part they didn’t include “woman”: auld wan (one) and auld biddy are the first two that come to mind. I can remember as a 20-year-old in university, feeling awkward about using the word “women” in relation to my female fellow students when “girls” seemed to be the more socially permissible term. Even today, there are some circles in which I’m cautious about calling a woman who plays a role on stage or screen an “actor”, in preference to the diminutive form of that word which is still commonly imposed on female dramatic performers.</p><p>In short, the identity of “woman” wasn’t one that the adult human females of the 1970s and 80s could expect would be easily accorded to them as their birthright. It had to be asserted, struggled for, fought over and repeatedly, exhaustingly, interminably insisted upon. Is it surprising that the women who played a part in establishing that identity should now be unwilling to give it up easily?</p><p>If you read J K Rowling’s <a href=\"https://www.jkrowling.com/opinions/j-k-rowling-writes-about-her-reasons-for-speaking-out-on-sex-and-gender-issues/\">recent post</a> <em>as she wrote it</em>, rather than through the lens of trans rights activists’ assumptions about the kind of thing a TERF is likely to say, I think it’s clear that her concern is not to express bigotry towards or hatred of trans people but rather to protest against the erasure of the hard-won identity of “woman” as meaning adult human female. Here is some of what she has to say:</p><blockquote>We’re living through the most misogynistic period I’ve experienced … Never have I seen women denigrated and dehumanised to the extent they are now. From the leader of the free world’s long history of sexual assault accusations and his proud boast of “grabbing them by the pussy”, to the incel (“involuntarily celibate”) movement that rages against women who won’t give them sex, to the trans activists who declare that TERFs need punching and re-educating, men across the political spectrum seem to agree: women are asking for trouble. Everywhere, women are being told to shut up and sit down, or else.</blockquote><p>You might not agree that the present state of the world threatens and attacks women (women in general, that is, not only trans women) but you surely must accept that Rowling has good reasons for her concerns. And, if you think that that calling out “trans activists who declare that TERFs need punching” is inexcusable exaggeration, just search Twitter for “punch a TERF” and prepare to be appalled. What you will see is the threat of (sometimes extreme) violence against people who are unquestionably women by people who (though some of them repudiate a <em>male identity</em>) are behaving in an undeniably masculine manner. Rowling adds:</p><blockquote>It’s also clear that one of the objectives of denying the importance of sex is to erode what some seem to see as the cruelly segregationist idea of women having their own biological realities or — just as threatening — unifying realities that make them a cohesive political class.</blockquote><p>It should be obvious from this that her purpose is not to be horrid to people who are struggling bravely under the burden of gender dysphoria, but to assert the importance of women (in the admittedly contested sense of human females) as an indispensable political force in a world that’s facing a whole series of crises.</p><p>Twitter is obviously not the ideal place to conduct a nuanced argument but even by its standards there’s been a remarkable amount of “reading in” to her tweets. In the one that sparked the current shouting match, she suggested that phrases like “people who menstruate” (or, by analogy, “pregnant people”) tend to erase women’s identity. Is she wrong?</p><p>I haven’t discussed the subjects of menstruation or the possibility of pregnancy with any trans men, but I’m fairly certain that for most trans men menstruation and pregnancy are not essential parts of their identity or self-conception. I doubt very much if many of them would feel offended or excluded by the use of terms like “menstruating women” or “pregnant women”. It’s clear, surely, that the overwhelming majorities of people who menstruate or who are pregnant are going to be women, so why should it be considered hateful or bigoted to talk about “women” in this context, unless as part of a project to make adult females less visible?</p><p>I hope I don’t need to point out that it’s a logical fallacy to infer that because people who menstruate are (by and large) women that therefore all women menstruate. But of course Rowling’s tweet about menstruating people wasn’t her only “offence”. I’m tempted to go into her expressed views about Maya Forstater’s sacking or the difficulties faced by detransitioners, but I’m afraid that each of these subjects would require its own post.</p><img src=\"https://www.artkavanagh.ie/stfu-terf.jpg\" alt=\"STFU TERF\" width=\"640\" height=\"805\"><p>So instead, I’d like to return to the question of misogyny. There’s <a href=\"https://medium.com/p/78e01dca68d\">a Medium post</a> by <a href=\"https://medium.com/@rebeccarc/\">boodleoops</a> who assembles a collection of screenshots of the Twitter attacks on Rowling. Some of them can be seen in the image above, but there are many more, and worse. Tweet after tweet tells Rowling to “shut the fuck up”, describes her as a TERF and a cunt, speculates as to how much her “pussy” stinks and/or has dried up, and invites her to choke on a trans girl’s dick.</p><p>How can anybody imagine that this vicious outpouring is prompted by anything <em>other than</em> misogyny? The hatred of women and disgust at female bodies is palpable throughout these tweets. Several are variants on “JK Rowling can choke on my fat trans cock”. Is it really credible that the persona behind this, who positively exults both in having a “cock” or a “dick” and in the prospect of using it as a weapon to silence a woman, either has a feminine gender identity or experiences dysphoria at having been assigned a masculine one?</p><p>I wrote “persona”, rather than “individual” because it occurs to me that some of the most offensive of these tweets may be the work, not of sincere trans rights activists, but of bots or alt-right trolls who relish the opportunity to set feminists and other ostensibly progressive people at each others’ throats. But whoever is responsible for this invective, it’s violently misogynist and ought to be rejected out of hand by anyone who calls herself a woman, whether trans or not.</p><p>The clash of identities often leads to irreconcilable and mutually contradictory claims, not just when it comes to questions of sex and gender but also in areas such as national identity. Usually, there’s no impartial, objective authority to whom a final, decisive appeal may be made, so the conflict may be irresolvable. In the dispute between veteran feminists (those who remember a time before adult human females were “women”) and trans activists, most of whom seem unable to conceive of any reason apart from “bigotry” why anyone might want to deny that trans women are female, I find myself uneasily on the side of the former, notwithstanding my self-description as “antimasculine”. This is because, for most of my adult life, I’ve been accustomed to think of gender <em>not</em> as identity but rather as <em>behaviour</em>, specifically as certain clusters of behaviours that were more or less masculine or feminine. In the third part of this series of posts, I’m planning to reexamine my long-held concept of gender-as-behaviour, to see whether it still has anything useful to tell us.</p>",
			"summary": "I got through most of my adult life without ever thinking about gender as a question of identity. It’s normal for clashes over identity to lead to mutually contradictory, incompatible claims, and ultimately irresolvable disputes. “Woman” is a contested identity.",
			"url": "https://www.artkavanagh.ie/gender-identity.html"
		},
		{
			"id": "a-good-masculinity-anti",
			"date_published": "2020-07-05T13:35:00+01:00",
			"title": "A good masculinity is hard to find: Part 1 — episodes from the early life of an antimasculine male",
			"content_html": "<p>About three years ago, I posted a piece (which I’ve since deleted) on Medium, attempting to explain why I don’t like to be described as “cisgender”. That post drew responses from several trans women (one of whom, ironically enough, accused me of “cisplaining”). Another made two telling points. First, she said it was OK not to want to use the term cisgender, but it was my responsibility to come up with an alternative. I didn’t have an immediate answer. It took a while but eventually I found a self-description that I’m happy with. The term is “antimasculine male”. (I’ll attempt to deal with her second point in part 2.)</p><p>Since reading the responses to that Medium post, I’ve been trying on and off to write something describing my thoughts, feelings and beliefs on the subject of gender. Each time, I find my argument drifting into a more theoretical and dogmatic stance than I meant it to. J K Rowling’s recent tweets <a href=\"https://www.jkrowling.com/opinions/j-k-rowling-writes-about-her-reasons-for-speaking-out-on-sex-and-gender-issues/\">and post</a> about trans men, women and activists has persuaded me that I need to try again. What follows below is <em>not</em> my latest attempt. It has occurred to me more than once that the main problem with the posts I’ve been drafting is that they’ve tended to be abstract and impersonal. Maybe, instead of writing about masculinity and femininity, (and men and women) in general, I needed to write about myself in particular.</p> <p>I can think of three times in my life when something closely related to my gender has been in question to some degree. The most recent of these happened more than 30 years ago, when I was on honeymoon in Paris. My then wife and I were staying in a two-star hotel on the Boulevard St Michel, in a room which had a partial view of Nôtre Dame. The room didn’t have its own w.c. or shower, so I had to go along the corridor to use them. I didn’t then and still don’t wear pyjamas, and I was travelling lightish, without my own dressing-gown. Rather than put my clothes back on, I borrowed my wife’s dressing-gown which was pink and obviously meant to be worn by a woman.</p><p>On my return to the room, my wife snapped a picture of me, using an old Kodak Instamatic which was the only camera we had at the time. When we were back in Dublin and the photos were developed, some weeks later, we were showing the honeymoon pictures to some of her friends.</p><p>“Who’s the girl?” one of them asked.</p><p>“Oh, that’s Art”, my wife answered.</p><p>I had at the time curly, brown hair which I was wearing long. I looked at the picture: in it I really <em>did</em> look like a young woman, one with a narrow, tapering face. I assume I was embarrassed, but what I most remember about the incident now is being pleased that I had “passed” — albeit in a poor quality, autofocused snapshot — and without a wig or makeup.</p><p>The previous time was nearly 15 years earlier. I was about 14 and I’d gone to the races with my aunt and some of her friends. I was coming out of the Gents and a man passing me in the opposite direction stopped dead and did a double-take, then looked up at the sign to make sure he was going into the right place. At that time, too, I had long, curly, brown hair and I was wearing faded denim jeans and a more-or-less matching light blue poloneck jumper (sweater). I think I probably had my arms folded, possibly giving the impression of a girl self-consciously hiding her breasts. I <em>was</em> self-conscious, partly because I was tall and skinny and didn’t know where to keep my arms and hands. The man’s reaction made my self-consciousness worse and I worried about what kind of image I was projecting. That incident, the least consequential of the three, was possibly the one I found most disconcerting.</p><p>The earliest time may have been the most significant in its long-term effects. When I was five years old, I was in the “High Infants” class in the local primary school. I can’t remember why, but we all had to take off our outer clothes. Presumably it was because we needed to be vaccinated or treated for headlice or some similar infestation. To the best of my recollection, it was something “medical”. Suddenly, it seemed that everyone was pointing at me and laughing. “Kavanagh has girl’s underpants”, more than one person said. I blushed and hotly denied it, but the more I insisted that there was nothing out of the ordinary about my underwear, the less I managed to persuade anyone, and the angrier I got. I had a dizzying sense that the situation had slipped irretrievably out of my control and that <em>I shoudn’t have allowed this to happen</em>, if I’d been paying attention properly. In the end, I probably had a meltdown. I went home at lunchtime and told my mother what had happened. She assured me that my underwear was perfectly gender-appropriate and I went back to school after lunch in a jubilant mood, armed with the facts and ready to set my classmates straight.</p><p>It didn’t work. Even my mother’s authoritative pronouncement didn’t manage to outweigh the evidence of my classmates’ own eyes. The difference between the boys’ underwear and the girls’ was insignificant but easily detectable. In both cases, the garments were plain white cotton, but while the girls’ had Aertex-style little perforations, the boys’ had a combed effect, resulting in stripes like a carefully mown lawn. (Or maybe it was the other way around. In any case, there was an obvious distinction.) And there was no denying that mine, uniquely among the boys, fit the same pattern as the girls’. My mother was wrong and the collective wisdom of High Infants had been vindicated.</p><p>It was a heady experience for a five-year-old. The embarrassment and humiliation of having been exposed to the whole class as a secret (if unwitting) crossdresser seemed almost literally unbearable, yet I couldn’t see that I had any choice but to bear it. I felt a sense of dismay so excruciating that it seemed impossible that I could continue to exist. This <em>couldn’t</em> be happening. I wanted to run away from the school and never come back. But, at the same time, I was turned on by the experience. The terrible humiliation was also unexpectedly arousing. As you can imagine, this was an unfamiliar sensation to me as a five-year-old.</p><p>Did this actually happen? I’m 99 point something percent sure that it did, though I have to admit that it seems unlikely that a class of 5-year-old boys and girls would be asked to get partly undressed in the course of the school day. I can remember the short-lived sense of relief as I walked back to school after lunch, with my mother’s assurance that, no, I was not wearing girl’s underwear. There was a particular boy (whose name I remember) who managed to quell the jeering of the others. I remember asking him the following day for advice on how to behave towards those classmates. To the best of my recollection his advice was to carry on as normal and try to live it down. I know I was disappointed. I had been hoping he knew of a way to roll back time and make this thing not have happened: to allow events to unfold the way they <em>ought</em> to have done, not the way they had. An escape into a parallel universe would have been acceptable.</p><p>Momentous though the experience was, I seem to have forgotten about it very quickly. I went through school, my teenage years, university, early work life and my marriage without ever consciously thinking about the incident. When, in my 30s, the memory resurfaced, I was astonished that it could have remained buried or hidden for so long. At the time, I thought I must have suppressed the recollection as traumatic. Only recently, much later, have I come to see that missing childhood memories don’t require any special explanation. I have “<a href=\"https://medium.com/p/2db66c17c5f3\">severely deficient autobiographical memory</a>” (SDAM), or <a href=\"https://medium.com/p/c48404d656c4\">something closely approaching it</a>. As a result, I don’t have <em>any</em> vivid childhood memories, or much in the way of vivid memories from any other period of my life. All the memories I have of my childhood, including my classmates’ ridicule of my underwear at the age of 5, are in the nature of bare narratives. I may remember <em>that</em> something happened but not how people looked, where they were sitting or standing, how the room was lit or decorated, or much of what was said. I usually don’t even know who was there, unless it’s particularly relevant. There’s no visual element, in short: each memory is more like a ledger entry than a snapshot. So, there’s nothing out of the ordinary about my having forgotten that particular incident, and it doesn’t necessarily involve any element of repression, though from my mid 30s to my late 50s I believed that it must have done. If there’s a question that needs to be answered, it’s not why I forgot about that incident, but rather why it suddenly popped back into my memory, so many years later.</p><p>What effect did these relatively early experiences have on my ideas and feelings about gender? It seems inevitable that they (the earliest one in particular) must have had some, though even now, having thought about these and related questions frequently over a thirty-five year period, I don’t feel any closer to an answer. I certainly have blind spots when it comes to gender. For example, it’s only quite recently that it’s occurred to me to ask why, as a five-year-old, I was wearing girl’s underwear in the first place? When I eventually remembered that episode, I think I initially just assumed that my mother must have bought underwear in bulk for me and my sisters and doled it out to us indiscriminately. But when I was 5, my youngest sister hadn’t yet been born and the two others were aged 2 and 1 respectively. The oldest I could possibly have been while at that school is 6, at which time my sisters would have been 3 and 2. So, it’s clearly not the case that my mother was buying the same underwear for all of us. Whether deliberately or inadvertently, she bought that “feminine” underwear specifically for me. I’d really like to know why, though even it I had thought of asking my mother during her lifetime, I feel sure that I’d have balked at the prospect. So, I’ll never know definitively, and I can’t resist speculating.</p><p>I intend this to be the first of three posts. In the second, I’m going to examine the concept of <em>gender identity</em>, and in the third I’ll look at <em>gender-as-behaviour</em>.</p>",
			"summary": "For some time, I’ve been trying to write about gender in general, even abstract, terms. But first I think I need to give an account of some of my own personal history as it relates to gender. This post is the first of three parts: the next two will deal respectively with gender identity and gender as behaviour.",
			"url": "https://www.artkavanagh.ie/a-good-masculinity-anti.html"
		},
		{
			"id": "PDF-small-screens",
			"date_published": "2020-06-27T17:50:00+01:00",
			"title": "PDF is preferable to ePub, even on small screens",
			"content_html": "<p>Over a period of months, I’ve been moving <a href=\"https://www.artkavanagh.ie/fiction-list.html\">my fiction</a> from Medium to this site. Only two pieces have still to be moved: my novel <cite>A Falling Body</cite> and a longish (7,500 word) three-part story that I’m not happy with and that I think needs to be rewritten or abandoned.</p><p>I originally wrote <cite>A Falling Body</cite> in eight chapters averaging 9,000 words each. For posting to Medium I split each chapter into four (or in one case six) smaller parts. So, the Medium version consists of 37 individual HTML pages. I’ve decided to reintegrate the chapters to post them here in nine parts (eight chapters plus three short appendices).</p><p>Looking at the vanity metrics on Medium, I notice that the first part of <cite>A Falling Body</cite> is still getting page views and reads, but these fall off precipitously after three or four parts. Some of the later parts of the story have had no views at all, and none has more than a handful. Much the same is true of the other stories that I’ve posted in multiple parts: <a href=\"https://www.artkavanagh.ie/fiction/Stockholm-part-1.html\"><cite>Dear Old Stockholm</cite></a>, a 21,000-word novella in six parts; and “<a href=\"https://www.artkavanagh.ie/fiction/protected-part-1.html\">Protected</a>”, a 9,500-word long short story (or <a href=\"https://medium.com/p/b20dc5452b23\">novelette</a>) in five.</p><p>Because of this rapid fall-off in views, I’ve been thinking that I should, at the end of each part, offer readers the option of downloading the whole story as a PDF. I have in the past been <a href=\"https://medium.com/p/9d3fac7aae42\">dismissive of ebooks</a> and I’ve no intention of <a href=\"https://www.artkavanagh.ie/ebooks-could-be-real-books.html\">recanting my criticism</a>. It does strike me, though, that PDFs avoid at least some of the disadvantages of ePub (and the related Kindle formats). If the ePub imitates the printed book in arbitrary, unconvincing and often unnecessary ways, the PDF is at least a closer approximation, though of course it too fails to replicate the physical characteristics of print.</p><p>In other words, I think the conventional wisdom may be wrong about the relative merits of ePub and PDF in the online dissemination of long form writing. As I understand it, the prevailing view is that ePubs are preferable because of their flexibility. The text will reflow to fit the viewport, making it possible for someone to read the same document on any arbitrarily sized screen, from tiny phone to enormous desktop monitor. The reader can choose the font size and (within fairly tight limits) face, easily search the text and add bookmarks and annotations.</p><p>What I think this argument gets wrong is that, while the sizes and proportions of the screens may vary widely, most people are going to want to view the text in a window that doesn’t diverge hugely from the dimensions of a typical book. Phones are bigger than they used to be, so I think it’s safe to assume that almost nobody will be reading on a screen smaller than 5in.. I calculated that a screen which is 5in. diagonally will be 2.8in. in width and 3.78in. in height, and used that as my starting point. Having tried out several possibilities, I eventually settled on 4in. × 6in., with a font size of 10pt and quarter-inch (18pt) margins. I could read <a href=\"https://www.artkavanagh.ie/protected.pdf\">the resulting PDF</a> on the 4in. screen of an iPod touch, albeit in landscape mode.</p><p>I opened the same PDF on an iPad and a two notebooks (one Mac, one Windows). They all zoomed in, so that the text appeared quite large, but it wasn’t outrageously so. I think I’ve found my optimal page size.</p><p>HTML is still my preferred format, even for long texts, but I accept that some readers would prefer an offline-readable version of the text, contained in a single document. For these purposes, I’ve concluded that PDF is a less unsatisfactory format than ePub. Besides, it gives me an excuse to play with the <a href=\"https://www.smashingmagazine.com/2015/01/designing-for-print-with-css/\">Paged Media module</a> of CSS.</p>",
			"summary": "The conventional wisdom may be wrong as to the relative merits of PDF and ePub in the dissemination of long form texts.",
			"url": "https://www.artkavanagh.ie/PDF-small-screens.html"
		},
		{
			"id": "writing-purpose",
			"date_published": "2020-06-14T11:13:00+01:00",
			"title": "I forgot the future: SDAM, aphantasia and a purpose in life",
			"content_html": "<p>About 2½ years ago, I sat in a psychotherapist’s office and she asked me what I wanted to do with the rest of my life. I had no idea. I made an effort to come up with an answer but it didn’t sound convincing to either of us. The therapist either decided that it would be a waste of time to try to get anything more out of me, or felt she had already planted the seed of further reflection that would bear fruit much later. Either way, she quickly moved on.</p><p>At the time, I was almost 60, and I found laughable the notion that it might be worth a person’s while actively to seek fulfilment in life. If occasionally a life turned out to be in some sense fulfilling, that was invariably the unplanned result of chance. There seemed no point in pursuing a purpose or goal in life when one’s own efforts could have no perceptible effect on the results. For most of its duration, my life had been aimless. That didn’t seem particularly regrettable. It was just normal.</p><p>There’s a song by Joe Jackson that goes “<a href=\"https://songwhip.com/joe-jackson/you-cant-get-what-you-want-till-you-know-what-you-want\">You can’t get what you want till you know what you want</a>”. I always used to sing “You can’t get what you want <em>if</em> you know what you want”. Not because I’d misheard the words — I knew exactly what they were meant to be — but because I thought my version was closer to the truth.</p><p>When I was seeing the psychotherapist I didn’t yet know that I have aphantasia. I had read Blake Ross’s post on the subject some time before and felt a momentary flash of recognition. I made a note of the URL, intending to go back later and digest his credulity-straining assertion that a majority of people can actually <em>see</em> things — like, inside their heads! It wasn’t till two years later that I rediscovered the URL, and this time the sense of recognition stuck.</p><p>In the months after I accepted that I have aphantasia, I began to think that my lifelong aimlessness might in part result from my incapacity for visualization. Though I haven’t been diagnosed with SDAM (severely deficient autobiographical memory), <a href=\"https://medium.com/p/2db66c17c5f3\">I’m not in any real doubt that I have that condition</a> (which sometimes accompanies aphantasia). My memories are not graphic or vivid: they’re more in the nature of ideas, abstractions, concepts and narratives than of images; it’s a bit like having index cards or ledger entries instead of detailed descriptions.</p><details><summary>Note: SDAM and aphantasia</summary>There’s a very informative paper by Nicholas Wynn Watkins, titled “(A)phantasia and Severely Deficient Autobiographical Memory: Scientific and Personal Perspectives”, freely available for <a href=\"https://www.google.co.uk/search?q=%22Nicholas+Wynn+Watkins%22+SDAM+aphantasia\">download in PDF from various websites</a>.</details><p>My mental conception of the past is dull, unexciting, featureless and full of gaps. Eventually it dawned on me that this is equally true of my conception of the future. After all, there’s no reason why my prospective imagination should be any clearer or sharper than my retrospective one. I don’t “remember” the future any better than I do what has already happened. If most people have at least some vivid, replayable “episodic” memories, isn’t it reasonable to suppose that they view the future in an analogous way? That they can actually “picture” themselves, attending <em>that</em> college, going on holiday to <em>that</em> exotic location, searching for a new job, buying and living in <em>that</em> house? Of course, I’m not suggesting that these imagined glimpses of the future are accurate. I don’t kid myself that most visualizers have a precognitive faculty. What I <em>am</em> suggesting is that these pictures of an imagined future, however misleading they eventually turn out to be, can constitute a target and roadmap that remain stable and consistent long enough to support a sustained pursuit.</p><p>It seems that consistency and stability are the key. It’s easy enough to decide that I’m going to be a more diligent and conscientious person than I have been, or more open to experience, or any number of other things, but without some kind of visual support I just drift off the path, and usually sooner rather than later.</p><p>The fact is that I can’t really imagine any kind of future. Obviously, I couldn’t expect to imagine it <em>visually</em> but somehow I haven’t been able to imagine it conceptually or in the abstract either, at least not in any way that sticks and makes it a substantial target to aim for. I suspect that, for better or worse, human imagination is disproportionately dependent on the visual — and that remains true even for some/many of us who don’t have a visual imagination.</p><p>Anyway, the therapist’s question prompted some kind of self-examination on my part, not immediately, but more than a year later, after I’d had time to think through some of the implications of having aphantasia. And guess what? To my surprise, I <em>do</em> know what I want to do with my life. I want to write, and to get some kind of recognition for my writing. That now seems so obvious that I have trouble grasping the fact that I’ve gone for years — indeed decades — without recognizing it. Writing has always been the thing I’m best (and, I often think, the <em>only</em> thing that I’m really good) at. Sometimes, it has seemed that I’m prepared to go to excessive lengths to avoid admitting that.</p><p>Coming to this realization, however late, shows me that it’s not necessary to be able to <em>imagine things visually</em> in order to find a purpose in life, though the lack of a visual imagination may lead one to “look” in the wrong places. In other words, I’m not <a href=\"https://medium.com/p/82efe3df7fb3\">blaming</a> aphantasia or SDAM for the belatedness of my discovery. I’m very happy to know <em>now</em> what it is that I’m aiming for. I’m simply saying that a visual imagination, if I’d had one, would probably have made it harder to miss the path. On the other hand, it was never inevitable that in the absence of a visual imagination I would take so long to find my way, any more than it was for <a href=\"https://www.bbc.com/news/health-47830256\">people like Ed Catmull</a>. That’s just the way it turned out.</p><p>The curious thing is that, while I expect this discovery to make me feel significantly better about myself and my life, I <em>don’t</em> think it’s going to make a lot of difference to my behaviour. I <em>have</em> been writing, on and off, for about 30 years. That includes some unsuccessful attempts at drama, several college essays that I was quite pleased with (but <a href=\"https://www.artkavanagh.ie/finite-though-unbounded\">only one of which survives</a>), my <a href=\"https://repository.royalholloway.ac.uk/items/25031702-dea3-49c6-a9e6-c068852e5df4/1/\">doctoral thesis</a>, a handful of journal articles on the subject of Andrew Marvell, a <a href=\"https://medium.com/p/744ee7ac0d08\">self-published novel</a>, several <a href=\"https://www.artkavanagh.ie/fiction-list.html\">short stories</a> and a miscellany of posts over the past three years, <a href=\"https://medium.com/@artkavanagh\">first on Medium</a> and more recently on this site. The difference, if any, is that I’ll now give this activity priority and try to make it my central activity. Ideally, I’ll go about i a bit more purposefully. It also means that I’ll try to write more <a href=\"https://www.artkavanagh.ie/index.html#bookdiscuss\">critical book discussion</a> and <a href=\"https://www.artkavanagh.ie/fiction-list.html\">fiction</a>, and less about such topics as tech, <a href=\"https://www.artkavanagh.ie/Google-future-search.html\">search</a>, <a href=\"https://medium.com/p/362c76c295d0\">publishing</a> and <a href=\"https://www.artkavanagh.ie/web-good-old-days.html\">the future of the web</a>. I <em>do</em> have one more tech/publishing piece to write (on the relative merits of ePub and PDF as a format for books), but it will be short.</p>",
			"summary": "A psychotherapist asked me what I wanted to do with what was left of my life and I had no idea. But now I do. SDAM means that I don’t see the past in an episodic way. The same is true of the future, and that may have had implications for how I thought about my objectives in life.",
			"url": "https://www.artkavanagh.ie/writing-purpose.html"
		}
 	]
}
